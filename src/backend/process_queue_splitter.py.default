# This file is part of Open-Capture.

# Open-Capture is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.

# Open-Capture is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with Open-Capture. If not, see <https://www.gnu.org/licenses/gpl-3.0.html>.

# @dev : Nathan Cheval <nathan.cheval@outlook.fr>
# @dev : Oussama Brich <oussama.brich@edissyum.com>

import os
import sys
import time
import json
from kuyruk import Kuyruk
from flask_babel import gettext
from src.backend.functions import retrieve_config_from_custom_id
from src.backend.import_classes import _Files, _Splitter, _SeparatorQR, _Log
from src.backend.main import timer, check_file, create_classes_from_custom_id

kuyruk = Kuyruk()


@kuyruk.task(queue='splitter_§§CUSTOM_ID§§')
def launch(args):
    """
    Launch Splitter process on a file
    :param args:
    - file: file path
    - user_id: user id
    - custom_id: custom id
    - workflow_id: workflow id
    :return: N/A
    """
    start = time.time()
    created_batches = []

    if not retrieve_config_from_custom_id(args['custom_id']):
        sys.exit('Custom config file couldn\'t be found')

    database, config, regex, files, ocr, log, _, _, smtp, docservers, configurations, languages = create_classes_from_custom_id(
        args['custom_id'], True)
    task_id_watcher = database.insert({
        'table': 'tasks_watcher',
        'columns': {
            'title': os.path.basename(args['file']),
            'type': 'upload',
            'module': 'splitter',
        }
    })

    database.update({
        'table': ['monitoring'],
        'set': {
            'creation_date': time.strftime("%Y-%m-%d %H:%M:%S"),
            'status': 'running'
        },
        'where': ['id = %s'],
        'data': [args['task_id_monitor']]
    })

    log.task_id_watcher = task_id_watcher
    log.task_id_monitor = args['task_id_monitor']
    log.database = database

    batch_folder = files.get_random_string(15)
    batch_folder_path = f"{docservers['SPLITTER_BATCHES']}/{batch_folder}/"
    batch_thumbs_path = f"{docservers['SPLITTER_THUMB']}/{batch_folder}/"
    os.mkdir(batch_folder_path)
    os.mkdir(batch_thumbs_path)

    try:
        os.chmod(batch_folder_path, int('775', base=8))
        os.chmod(batch_thumbs_path, int('775', base=8))
    except OSError:
        pass

    files = _Files('', log, docservers, configurations, regex, languages, database)

    ocrise = False
    splitter_method_id = ''
    remove_blank_pages = False

    workflow_settings = database.select({
        'select': ['input, separation, process, output'],
        'table': ['workflows'],
        'where': ['workflow_id = %s', 'module = %s'],
        'data': [args['workflow_id'], 'splitter']
    })

    if workflow_settings:
        outputs = []
        if workflow_settings[0]['process']['use_interface'] and \
                'form_id' in workflow_settings[0]['process'] and workflow_settings[0]['process']['form_id']:
            outputs = database.select({
                'select': ['outputs'],
                'table': ['form_models'],
                'where': ['id = %s'],
                'data': [workflow_settings[0]['process']['form_id']]
            })
            if outputs:
                outputs = outputs[0]['outputs']
        else:
            outputs = database.select({
                'select': ['output'],
                'table': ['workflows'],
                'where': ['workflow_id = %s', 'module = %s'],
                'data': [args['workflow_id'], 'splitter']
            })
            if outputs:
                outputs = outputs[0]['output']['outputs_id']

        args['customer_id'] = workflow_settings[0]['input']['customer_id']
        splitter_method_id = workflow_settings[0]['separation']['splitter_method_id']
        remove_blank_pages = workflow_settings[0]['separation']['remove_blank_pages']
        for output_id in outputs:
            outputs_settings = database.select({
                'select': ['ocrise'],
                'table': ['outputs'],
                'where': ['id = %s'],
                'data': [int(output_id)]
            })
            if outputs_settings:
                ocrise = outputs_settings[0]['ocrise']

    separator_qr = _SeparatorQR(log, config, batch_folder_path, 'splitter', files, remove_blank_pages, docservers,
                                splitter_method_id)
    splitter = _Splitter(config, database, separator_qr, log, docservers)

    if args.get('isMail') is not None and args['isMail'] is True:
        log = _Log((args['log']), smtp)
        log.info('Process attachment n°' + args['cpt'] + '/' + args['nb_of_attachments'])

    database.connect()
    process_err = False

    try:
        if args['file'] is not None:
            path = args['file']
            if check_file(files, path, log, docservers) and not process_err:
                if 'workflow_id' in args and args['workflow_id']:
                    available_split_methods_path = docservers['SPLITTER_METHODS_PATH'] + "/splitter_methods.json"
                    if splitter_method_id and os.path.isfile(available_split_methods_path):
                        with open(available_split_methods_path, encoding='UTF-8') as json_file:
                            available_split_methods = json.load(json_file)
                            for available_split_method in available_split_methods['methods']:
                                if available_split_method['id'] == splitter_method_id:
                                    split_method = _Splitter.import_method_from_script(
                                        docservers['SPLITTER_METHODS_PATH'],
                                        available_split_method['script'],
                                        available_split_method['method'])
                                    log.info('Split using method : {}'.format(available_split_method['id']))
                                    split_args = {
                                        "log": log,
                                        "ocr": ocr,
                                        "file": path,
                                        "regex": regex,
                                        "files": files,
                                        "ocrise": ocrise,
                                        "config": config,
                                        "splitter": splitter,
                                        "docservers": docservers,
                                        "user_id": args['user_id'],
                                        "batch_folder": batch_folder,
                                        "configurations": configurations,
                                        "workflow_id": args['workflow_id'],
                                        "customer_id": args['customer_id'],
                                    }
                                    split_res = split_method(split_args)
                                    created_batches = split_res['batches_id']
                else:
                    process_err = True
                    log.error("The workflow_id doesn't exists in database")
            else:
                process_err = True

            auto_validation = not workflow_settings[0]['process']['use_interface'] \
                              or workflow_settings[0]['process']['allow_automatic_validation']
            if not process_err and auto_validation:
                for batch_id in created_batches:
                    export_batch(batch_id, log, docservers, configurations, regex)

    except Exception as _e:
        process_err = True
        _e = _e.__class__.__name__ + ' : ' + str(_e)
        log.error(_e)

    if not process_err:
        database.connect()
        database.update({
            'table': ['tasks_watcher'],
            'set': {
                'status': 'done',
                'end_date': time.strftime("%Y-%m-%d %H:%M:%S")
            },
            'where': ['id = %s'],
            'data': [task_id_watcher]
        })
    end = time.time()
    _timer = timer(start, end)
    log.info('Process end after ' + _timer + '')
    database.update({
        'table': ['monitoring'],
        'set': {
            'document_ids': created_batches,
            'elapsed_time': _timer,
            'status': 'done',
            'end_date': time.strftime("%Y-%m-%d %H:%M:%S")
        },
        'where': ['id = %s'],
        'data': [args['task_id_monitor']]
    })
    database.conn.close()
